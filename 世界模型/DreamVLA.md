使用非生成式世界预测，专注于预测关键的“世界知识”
### 创新点

引入**世界嵌入 (World Embeddin)**，来预测三种关键的世界知识，作为行动规划的线索
#### 1. 综合世界知识预测

- **动态区域预测 (Dynamic Region-Based Forecasting):**
    - **方法：** 不直接预测密集的**光流**，而是利用预训练的 CoTracker 模型识别场景中的**动态区域（与机器人末端执行器或可移动物体相关的像素）**。
    - **优势：** 允许模型专注于任务执行关键的运动区域，而非冗余的背景重建，从而实现更高效、结构化的动作推理。这被实验证明是所有预测类型中贡献最大的。
- **深度感知预测 (Depth-Aware Forecasting):**
    - **方法：** 通过深度估计算法（如 Depth-Anything v2）生成每帧的深度图。在没有真实深度数据时，模型会“幻化”未来几何形状。
    - **优势：** 提供有价值的空间上下文，帮助模型理解环境的三维结构，指导机器人避开障碍物并走向自由空间，对于抓取合成和碰撞检测至关重要。
- **高层语义特征预测 (High-Level Foundation Features):**
    - **方法：** 整合来自视觉基础模型（如 DINOv2 和 SAM）的语义特征。
    - **优势：** 提供高层上下文（如物体身份和功能），指导目标选择和抓取方式，提高模型的泛化能力。

#### **2. 结构化注意力机制

- **问题：** 动态、空间和语义信息在训练过程中相互干扰，可能导致信息泄漏和表示混合。
- **解决方案：** DreamVLA 采用**块状结构化注意力机制**，对不同类型的知识（动态、深度、语义）之间的相互注意力进行遮蔽。
- **优势：** 确保每种表示的**纯净性和解耦性**，防止高频流细节污染深度推理，或语义线索渗入运动特征，从而实现连贯的多步动作推理。
  
#### **3. 基于扩散的 Transformer (Diffusion-Based Transformer) 用于动作生成**

- **问题：** 世界嵌入和动作嵌入共享相同的潜在空间和统计特性，朴素的 MLP 头部难以解耦特定模态信息或利用跨模态关联。
- **解决方案：** 使用**去噪扩散 Transformer (DiT)** 作为动作头部，从共享潜在特征中解耦动作表示，以推理生成动作序列。
- **优势：** 能够灵活建模复杂动作分布，通过迭代去噪过程将高斯噪声转换为 n 步动作序列，生成连贯、多样且物理合理的动作。
  
### 架构
![[Pasted image 20250921093716.png]]

- 语言指令 (l)、视觉观测 (ot) 和本体状态 (st)通过编码器作为知识输入
- dream查询token引导生成世界嵌入知识
- 动作查询token提取动作嵌入，结合世界嵌入知识，生成动作序列