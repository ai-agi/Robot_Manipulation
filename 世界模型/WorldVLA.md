动作模型+生成式世界模型
![[Pasted image 20250921101859.png]]
![[Pasted image 20250921102157.png]]
所有经过 Tokenizer 处理后的**图像、文本和动作令牌**都被送入一个**单一的 LLM 架构**中。这个 LLM 架构从 Chameleon 模型初始化，因为它本身就是一个统一的图像理解和生成模型。

- **自回归性质：** 模型以自回归的方式进行训练，这意味着它在生成一个令牌时，会基于所有先前的令牌（包括图像、文本和已生成的动作/图像令牌）进行预测。
- **共享词汇表：** 所有模态的令牌共享相同的词汇表，使得 LLM 能够无缝地处理和生成不同类型的信息。
  
**数据流：**
- **输入：**
    - **文本 (Text):** 任务指令 ("What action should the robot take to ?")。
    - **图像 (Image):** 当前的视觉观测帧。
    - **动作 (Action):** 在世界模型模式下，需要输入当前动作来预测下一帧。
- **输出：**
    - **动作 (Action):** 在动作模型模式下，生成机器人要执行的动作。
    - **图像 (Image):** 在世界模型模式下，预测下一帧图像。

训练：通过混合两种类型的数据来训练，使其能够同时执行动作模型和世界模型的功能